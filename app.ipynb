{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8491a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langfuse.langchain import CallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(prompt: str, model: str = \"gpt-4.1\", timeout: int = 60) -> str:\n",
    "    \"\"\"\n",
    "    Send prompt to internal LLM API gateway. Returns the response text.\n",
    "    Uses TokenFetcher for auth and Langfuse for observability.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Setup Environment Credentials\n",
    "        os.environ['LLM_CLIENT_ID'] = os.getenv(\"LLM_CLIENT_ID\")\n",
    "        os.environ['LLM_CLIENT_SECRET'] = os.getenv(\"LLM_CLIENT_SECRET\")\n",
    "\n",
    "        # 2. Specific Langfuse Config\n",
    "        LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "        LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "        LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\")\n",
    "\n",
    "        # 3. Initialize Authentication\n",
    "        token_fetcher = TokenFetcher(\n",
    "            client_id=os.getenv('LLM_CLIENT_ID'),\n",
    "            client_secret=os.getenv('LLM_CLIENT_SECRET'),\n",
    "            auth_url=\"https://auth.llm.ai/oauth2/token\",\n",
    "            scope=\"llm.openai.api\"\n",
    "        )\n",
    "\n",
    "        # 4. Initialize Observability (Langfuse)\n",
    "        # The import path was fixed to use langfuse.langchain\n",
    "        langfuse_handler = CallbackHandler(\n",
    "            public_key=LANGFUSE_PUBLIC_KEY,\n",
    "            secret_key=LANGFUSE_SECRET_KEY,\n",
    "            host=LANGFUSE_HOST\n",
    "        )\n",
    "\n",
    "        # 5. Initialize the LLM Client\n",
    "        llm = ChatOpenAI(\n",
    "            model=model,\n",
    "            # 'base_url' is preferred over 'openai_api_base' in newer langchain versions\n",
    "            api_key=token_fetcher.token, \n",
    "            temperature=0,\n",
    "            callbacks=[langfuse_handler],\n",
    "            request_timeout=timeout\n",
    "        )\n",
    "\n",
    "        # 6. Invoke the model\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = llm.invoke(messages)\n",
    "\n",
    "        return response.content\n",
    "\n",
    "    except ImportError as e:\n",
    "        return f\"[LLM-error] Missing dependency: {e}. Try: pip install langfuse langchain-openai\"\n",
    "    except Exception as e:\n",
    "        return f\"[LLM-failed] {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db726f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6a8e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Month', 'Year', 'Retail_RO_Obj', 'Retail_RO_Act', 'Rev/RO_Obj',\n",
      "       'Retail_Traffic_FL', 'Rev/RO Act', 'Battery_RO', 'Brake_RO', 'Wiper_RO',\n",
      "       'CVP_Score', 'CVP_Survey Returns', 'NPS_Score', 'NPS_Survey Returns',\n",
      "       'FIRFT_Score', 'FIRFT_Survey Returns', 'CVP_Score_3M',\n",
      "       'CVP_Survey Returns_3M', 'NPS_Score_3M', 'NPS_Survey Returns_3M',\n",
      "       'FIRFT_Score_3M', 'FIRFT_Survey Returns_3M', 'Total CRC Case',\n",
      "       'CRC Dealer', 'CRC Reactive', 'CRC Proactive'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ms128/Library/CloudStorage/OneDrive-azureford/Desktop/AI-Assistant/Australia_service.csv')\n",
    "print(df.select_dtypes(include='number').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7736f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_to_code(prompt: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert known prompt templates into runnable python code strings.\n",
    "    If the prompt is custom/unrecognized, return None (so UI can send to LLM instead).\n",
    "    \"\"\"\n",
    "    p = prompt.strip().lower()\n",
    "\n",
    "    # Summary\n",
    "    if p.startswith(\"summarize the dataset\"):\n",
    "        code = textwrap.dedent(\"\"\"\n",
    "            # produce a short summary as printed text\n",
    "            info = []\n",
    "            info.append(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "            info.append(\"Column types: \" + \", \".join([f\\\"{c}:{str(df[c].dtype)[:10]}\\\" for c in df.columns[:10]]))\n",
    "            miss = df.isnull().sum().sort_values(ascending=False).head(10)\n",
    "            info.append(\"Top missing: \" + \", \".join([f\\\"{idx}:{val}\\\" for idx,val in miss.items() if val>0]))\n",
    "            numeric = df.select_dtypes(include=['number']).columns.tolist()\n",
    "            info.append(f\\\"Numeric columns count: {len(numeric)}\\\")\n",
    "            # print concise bullets\n",
    "            result = \\\"\\\\n\\\".join([\\\"- \\\"+i for i in info])\n",
    "        \"\"\")\n",
    "        return code\n",
    "\n",
    "    # Top counts for categorical\n",
    "    if \"top 10 counts for the categorical column\" in p or \"top 10 counts\" in p and \"'\" in p:\n",
    "        # try to extract column name between quotes\n",
    "        import re\n",
    "        m = re.search(r\"'([^']+)'\", prompt)\n",
    "        if not m:\n",
    "            m = re.search(r'\"([^\"]+)\"', prompt)\n",
    "        col = m.group(1) if m else None\n",
    "        if col:\n",
    "            code = textwrap.dedent(f\"\"\"\n",
    "                # top 10 counts for '{col}'\n",
    "                result = df['{col}'].value_counts(dropna=False).head(10).reset_index()\n",
    "                result.columns = ['value','count']\n",
    "            \"\"\")\n",
    "            return code\n",
    "\n",
    "    # Summary statistics for numeric\n",
    "    if \"summary statistics\" in p or \"describe\" in p:\n",
    "        code = textwrap.dedent(\"\"\"\n",
    "            result = df.select_dtypes(include=['number']).describe().T\n",
    "        \"\"\")\n",
    "        return code\n",
    "\n",
    "    # Histogram\n",
    "    if p.startswith(\"create a histogram of the numeric column\") or \"histogram of the numeric column\" in p:\n",
    "        import re\n",
    "        m = re.search(r\"'([^']+)'\", prompt)\n",
    "        col = m.group(1) if m else None\n",
    "        if col:\n",
    "            code = textwrap.dedent(f\"\"\"\n",
    "                # histogram for '{col}'\n",
    "                plt.figure(figsize=(6,4))\n",
    "                df['{col}'].dropna().astype(float).hist(bins=30)\n",
    "                plt.title('Histogram of {col}')\n",
    "                plt.xlabel('{col}')\n",
    "                plt.ylabel('count')\n",
    "                # produce an image by saving to result_img_path variable\n",
    "                result_img_path = None\n",
    "            \"\"\")\n",
    "            # We'll return plotting code that uses plt; execution will save figure\n",
    "            return code\n",
    "\n",
    "    # Scatter plot\n",
    "    if \"scatter plot comparing\" in p and \"vs\" in p:\n",
    "        import re\n",
    "        m = re.search(r\"'([^']+)' \\\\(x\\\\) vs '([^']+)' \\\\(y\\\\)\", prompt)\n",
    "        if m:\n",
    "            xcol, ycol = m.group(1), m.group(2)\n",
    "            code = textwrap.dedent(f\"\"\"\n",
    "                plt.figure(figsize=(6,4))\n",
    "                df.plot.scatter(x='{xcol}', y='{ycol}')\n",
    "                plt.title('{ycol} vs {xcol}')\n",
    "                result_img_path = None\n",
    "            \"\"\")\n",
    "            return code\n",
    "\n",
    "    # Top N rows sorted by col\n",
    "    if p.startswith(\"show the top 10 rows sorted by\"):\n",
    "        import re\n",
    "        m = re.search(r\"by '([^']+)'\", prompt)\n",
    "        if m:\n",
    "            col = m.group(1)\n",
    "            code = textwrap.dedent(f\"\"\"\n",
    "                result = df.sort_values('{col}', ascending=False).head(10).reset_index(drop=True)\n",
    "            \"\"\")\n",
    "            return code\n",
    "\n",
    "    # Time series monthly sum\n",
    "    # if \"monthly sum\" in p and \"using the datetime column\" in p:\n",
    "    #     import re\n",
    "    #     m = re.search(r\"sum of '([^']+)' using the datetime column '([^']+)'\", prompt)\n",
    "    #     if m:\n",
    "    #         ag, dcol = m.group(1), m.group(2)\n",
    "    #         code = textwrap.dedent(f\"\"\"\n",
    "    #             tmp = df.copy()\n",
    "    #             tmp['{dcol}'] = pd.to_datetime(tmp['{dcol}'], errors='coerce')\n",
    "    #             res = tmp.dropna(subset=['{dcol}'])\n",
    "    #             res = res.set_index('{dcol}').resample('M')['{ag}'].sum().reset_index()\n",
    "    #             result = res\n",
    "    #         \"\"\")\n",
    "    #         return code\n",
    "\n",
    "    # Counts per month (datetime only)\n",
    "    # if \"counts per month using the datetime column\" in p:\n",
    "    #     import re\n",
    "    #     m = re.search(r\"datetime column '([^']+)'\", prompt)\n",
    "    #     dcol = m.group(1) if m else None\n",
    "    #     if dcol:\n",
    "    #         code = textwrap.dedent(f\"\"\"\n",
    "    #             tmp = df.copy()\n",
    "    #             tmp['{dcol}'] = pd.to_datetime(tmp['{dcol}'], errors='coerce')\n",
    "    #             res = tmp.dropna(subset=['{dcol}']).set_index('{dcol}').resample('M').size().reset_index(name='count')\n",
    "    #             result = res\n",
    "    #         \"\"\")\n",
    "    #         return code\n",
    "\n",
    "    # Correlation heatmap\n",
    "    if \"correlation matrix heatmap\" in p or \"correlation heatmap\" in p:\n",
    "        code = textwrap.dedent(\"\"\"\n",
    "            corr = df.select_dtypes(include=['number']).corr()\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure(figsize=(6,5))\n",
    "            plt.imshow(corr, cmap='viridis', aspect='auto')\n",
    "            plt.colorbar()\n",
    "            plt.xticks(range(len(corr)), corr.columns, rotation=90)\n",
    "            plt.yticks(range(len(corr)), corr.columns)\n",
    "            plt.title('Correlation matrix')\n",
    "            result_img_path = None\n",
    "        \"\"\")\n",
    "        return code\n",
    "\n",
    "    # Anomaly detection using z-score\n",
    "    if \"anomalies\" in p and \"z-score\" in p:\n",
    "      code = textwrap.dedent(\"\"\"\n",
    "          from scipy import stats\n",
    "          import numpy as np\n",
    "          import pandas as pd\n",
    "          \n",
    "          # Select numeric columns only\n",
    "          operational_cols = [\n",
    "          \"Retail_RO_Obj\",\n",
    "          \"Retail_RO_Act\",\n",
    "          \"Retail_RO_Parts_Revenue\",\n",
    "          \"Retail_Traffic_FL\",\n",
    "          \"Battery_RO\",\n",
    "          \"Brake_RO\",\n",
    "          \"Wiper_RO\",\n",
    "          \"Base_VIN\",\n",
    "          \"Retained_VIN\",\n",
    "          \"Non Retailed_VIN\",\n",
    "          \"Total CRC Case\",\n",
    "          \"CRC Dealer\",\n",
    "          \"CRC Reactive\",\n",
    "          \"CRC Proactive\"\n",
    "          ]\n",
    "\n",
    "          num = df[operational_cols].select_dtypes(include=['number'])\n",
    "          \n",
    "          # Compute z-score column-wise, ignoring NaNs\n",
    "          z = np.abs(stats.zscore(num, nan_policy='omit'))\n",
    "          \n",
    "          # zscore returns a numpy array; convert to DataFrame and align index\n",
    "          z_df = pd.DataFrame(z, columns=num.columns, index=df.index)\n",
    "          \n",
    "          # Mask: any z-score > 3 in any numeric column\n",
    "          mask = (z_df > 3).any(axis=1)\n",
    "          \n",
    "          # Show top 20 anomalies\n",
    "          result = df.loc[mask].head(20).reset_index(drop=True)\n",
    "      \"\"\")\n",
    "    return code\n",
    "\n",
    "    # Unknown / custom prompts -> return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead66b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(prompt: str, model: str = \"gpt-5-mini-2025-08-07\", timeout: int = 60) -> str:\n",
    "    \"\"\"\n",
    "    Send prompt to LLM API gateway. Returns the response text.\n",
    "    Uses TokenFetcher for auth and Langfuse for observability.\n",
    "    \"\"\"\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv()\n",
    "    \n",
    "    try:\n",
    "        # 1. Setup Environment Credentials\n",
    "        os.environ['CLIENT_ID'] = os.getenv(\"CLIENT_ID\")\n",
    "        os.environ['CLIENT_SECRET'] = os.getenv(\"CLIENT_SECRET\")\n",
    "\n",
    "        # 2. Initialize Authentication\n",
    "        token_fetcher = TokenFetcher() \n",
    "\n",
    "        # 3. Initialize Observability (Langfuse)\n",
    "        # The import path was fixed to use langfuse.langchain\n",
    "        # use the CallbackHandler class that we imported above\n",
    "        langfuse_handler = CallbackHandler()\n",
    "\n",
    "        # Get BASE_URL from environment variable\n",
    "        url = os.getenv(\"BASE_URL\")\n",
    "        if not url:\n",
    "            raise ValueError(\"BASE_URL is not set\")\n",
    "\n",
    "        # 4. Initialize the LLM Client\n",
    "        llm = ChatOpenAI(\n",
    "            model = model,\n",
    "            base_url = url,\n",
    "            api_key = token_fetcher.token, \n",
    "            temperature = 0,\n",
    "            callbacks = [langfuse_handler],\n",
    "            request_timeout = timeout\n",
    "        )\n",
    "\n",
    "        # 5. Invoke the model\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = llm.invoke(messages)\n",
    "\n",
    "        return response.content\n",
    "\n",
    "    except ImportError as e:\n",
    "        return f\"[LLM-error] Missing dependency: {e}. Try: pip install langfuse langchain-openai\"\n",
    "    except Exception as e:\n",
    "        return f\"[LLM-failed] {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ae424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
